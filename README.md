# ConvNeXt-CheXpert-Attention ğŸ¥

[![HuggingFace Model](https://img.shields.io/badge/%F0%9F%A4%97-Model%20Hub-yellow)](https://huggingface.co/calender/Convnext-Chexpert-Attention)
[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

Multi-label chest X-ray classifier: **ConvNeXt-Base + CBAM attention** trained on CheXpert to detect 14 thoracic pathologies.

**Model AUC: 0.81** | **Iteration 6** | **GradCAM Enabled** | **300MB**

ğŸ¤— [Get Model Weights on HuggingFace](https://huggingface.co/calender/Convnext-Chexpert-Attention)

---

## âš¡ Quick Demo

```python
import torch
from PIL import Image
from torchvision import transforms
import timm

# Load model
model = timm.create_model('convnext_base', pretrained=False, num_classes=14)
model.load_state_dict(torch.load('model.pth'))
model.eval()

# Predict
image = Image.open('chest_xray.jpg')
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),
    transforms.Resize((384, 384)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.503]*3, std=[0.289]*3)
])

with torch.no_grad():
    probs = torch.sigmoid(model(transform(image).unsqueeze(0)))
    
# Results: 14 pathology probabilities
```

See `examples/inference_example.py` for full code.

---

## ğŸ“– What This Does

Analyzes chest X-rays and predicts **14 pathologies**:

Edema â€¢ Cardiomegaly â€¢ Pleural Effusion â€¢ Atelectasis â€¢ Consolidation â€¢ Pneumonia â€¢ Fracture â€¢ Lung Opacity â€¢ Pneumothorax â€¢ Lung Lesion â€¢ Cardiomediastinum â€¢ Pleural Other â€¢ Support Devices â€¢ No Finding

**Includes GradCAM visualization** to see which regions the model focuses on for each prediction.

---

## ğŸš€ Getting Started

### 1. Setup

```bash
git clone https://github.com/jikaan/convnext-chexpert-attention.git
cd convnext-chexpert-attention

pip install -r requirements.txt

# Download model from HuggingFace
# https://huggingface.co/calender/Convnext-Chexpert-Attention
```

### 2. Inference

```bash
# Basic usage (requires model file)
python gituplod/src/gradcam_single.py --image path/to/xray.jpg --model hfupld/model/model.pth
```

### 3. GradCAM Visualization

```bash
# Single image analysis with multiple findings
python gituplod/src/gradcam_single.py --image path/to/xray.jpg --model hfupld/model/model.pth --output results.png
```

See `hfupld/` folder for sample visualizations (1.png, 2.png, 3.png, analysis.png).

---

## ğŸ“Š Performance

| Metric | Value |
|--------|-------|
| Validation AUC | 0.81 |
| Architecture | ConvNeXt-Base + CBAM |
| Dataset | CheXpert (224K images) |
| Input Size | 384Ã—384 |
| Model Size | 351MB |

**Examples from Test Set:**

| Pathology | Confidence | GradCAM |
|-----------|-----------|---------|
| Edema | 63.7% | ![](../hfupld/analysis.png) |
| Multiple Findings | 65.2% | ![](../hfupld/1.png) |
| Cardiomegaly | 67.2% | ![](../hfupld/2.png) |
| Pneumothorax | 63.1% | ![](../hfupld/3.png) |

---

## ğŸ“ Structure

```
chexpert-convnext-classifier/
â”œâ”€â”€ gituplod/                          # Repository files
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ gradcam_single.py          # Single image GradCAM analysis
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ train.py                   # Training script (iteration 3)
â”‚   â”œâ”€â”€ examples/
â”‚   â”‚   â””â”€â”€ test_images/               # Sample visualization outputs
â”‚   â”œâ”€â”€ LICENSE                        # Apache 2.0 License
â”‚   â”œâ”€â”€ README.md                      # This file
â”‚   â””â”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ hfupld/                           # Model and demo files
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ model.pth (351MB)          # Model weights
â”‚   â”‚   â””â”€â”€ model_config.json          # Model configuration
â”‚   â”œâ”€â”€ 1.png, 2.png, 3.png            # Single pathology GradCAM examples
â”‚   â”œâ”€â”€ analysis.png                   # Multi-disease visualization
â”‚   â””â”€â”€ README.md                      # Model card
â””â”€â”€ requirements.txt                   # Project dependencies
```

---

## ğŸ‹ï¸ Training

Reproduce results with iteration 3 training script:

```bash
python gituplod/training/train.py \
    --data_dir path/to/chexpert \
    --batch_size 4 \
    --epochs 3 \
    --lr 2e-5
```

**Training Config:**
- Optimizer: AdamW + Lookahead
- Loss: Focal Loss + uncertainty masking
- Augmentation: Crops, flips, rotation, color jitter
- Dataset: CheXpert (88% train, 2% val, 10% test)

See `gituplod/training/train.py` for full implementation.

---

## ğŸ’¡ Key Features

âœ… **CBAM Attention** - Better pathology localization  
âœ… **GradCAM Support** - Visual explanations  
âœ… **Multi-label** - Detects multiple pathologies simultaneously  
âœ… **Uncertainty Handling** - Trained with uncertain labels  
âœ… **Clean Code** - Iteration 3 training script included  

---

## âš ï¸ Important

**This is research code. Medical Disclaimer:**
- NOT for clinical diagnosis
- NOT FDA-approved
- Requires expert radiologist review
- See [LICENSE](LICENSE) for full terms

---

## ğŸ“ Citation

If you use this in research:

```bibtex
@software{convnext_chexpert_attention_2025,
  author = {Time},
  title = {ConvNeXt-Base CheXpert Classifier with CBAM Attention},
  year = {2025},
  url = {https://github.com/jikaan/convnext-chexpert-attention}
}

@article{irvin2019chexpert,
  title={CheXpert: A large chest radiograph dataset with uncertainty labels},
  author={Irvin, Jeremy and Rajpurkar, Pranav and Ko, Michael and others},
  year={2019}
}
```

---

## ğŸ”— Links

- **Model (HuggingFace):** https://huggingface.co/calender/Convnext-Chexpert-Attention
- **CheXpert Dataset:** https://stanfordmlgroup.github.io/competitions/chexpert/
- **Paper:** https://arxiv.org/abs/1901.07031

---

## ğŸ“§ Contact

Questions? Open an issue on GitHub.

**Created by Time | October 2025**